---
sidebar: sidebar
permalink: use/upgrade-acc.html
keywords: astra upgrade, upgrade astra control center, how to upgrade astra control, update
summary: To upgrade Astra Control Center, you'll download the bundle and upgrade following the steps described.
---

= Upgrade Astra Control Center
:hardbreaks:
:icons: font
:imagesdir: ../media/get-started/

[.lead]
To upgrade Astra Control Center, download the installation bundle from the NetApp Support Site and complete these instructions to upgrade the Astra Control Center components in your environment. You can use this procedure to upgrade Astra Control Center in internet-connected or air-gapped environments.

.What you'll need
* Before you upgrade, refer to link:../get-started/requirements.html#operational-environment-requirements[Operational environment requirements^] to ensure your environment still meets the minimum requirements for Astra Control Center deployment. Your environment should have the following:

** A supported Kubernetes distribution
To determine the version you are running, run the following command in your existing Astra Control Center container: `kubectl get nodes o -wide`
** Sufficient cluster resources
To determine cluster resources, run the following command in your existing Astra Control Center cluster: `kubectl describe node <node name>`
** A supported Astra Trident version
To determine the version you are running, run the following command in your existing Astra Control Center container:
+
----
../../trident-installer/tridentctl -n trident version
----
Refer to https://docs.netapp.com/us-en/trident/trident-managing-k8s/upgrade-trident.html#determine-the-version-to-upgrade-to[Astra Trident documentation] to upgrade from an older version.

** A registry you can use to push and upload Astra Control Center images 
** A default storage class
To determine your default storage class, run the following command in your existing Astra Control Center container: `kubectl get storageclass`

* (OpenShift only) Ensure all cluster operators are in a healthy state and available.
+
----
kubectl get clusteroperators
----

* Ensure all API services are in a healthy state and available.
+
----
kubectl get apiservices
----

* If you use or plan to use multiple namespaces with your apps in Astra Control, link:../use/manage-roles.html#add-a-namespace-constraint-to-a-role[modify user roles with namespace constraints] before you upgrade.
* Log out of your Astra Control Center UI before you begin the upgrade.

.About this task
The Astra Control Center upgrade process guides you through the following high-level steps:

* <<Download the Astra Control Center bundle>>
* <<Unpack the bundle and change directory>>
* <<Add the images to your local registry>>
* <<Install the updated Astra Control Center operator>>
* <<Upgrade Astra Control Center>>
* <<Upgrade third-party services (Optional)>>
* <<Verify system status>>
* <<Set up ingress for load balancing>>


IMPORTANT: Do not execute the following command during the entirety of the upgrade process to avoid deleting all Astra Control Center pods: `kubectl delete -f astra_control_center_operator_deploy.yaml`

TIP: Perform upgrades in a maintenance window when schedules, backups, and snapshots are not running.

NOTE: Podman commands can be used in place of Docker commands if you are using Red Hat's Podman instead of Docker Engine.

== Download the Astra Control Center bundle

. Download the Astra Control Center bundle from the https://mysupport.netapp.com/site/products/all/details/astra-control-center/downloads-tab[NetApp Support Site^]. The file name is similar to the following: `astra-control-center-[version].tar.gz`.

. (Optional) Use the following command to verify the signature of the bundle:
+
----
openssl dgst -sha256 -verify AstraControlCenter-public.pub -signature astra-control-center-[version].tar.gz.sig astra-control-center-[version].tar.gz
----

== Unpack the bundle and change directory

. Extract the images:
+
----
tar -vxzf astra-control-center-[version].tar.gz
----

== Verify that you have the NetApp Astra kubectl plugin installed
The NetApp Astra `kubectl` command line plugin saves time when performing common tasks associated with deploying and upgrading Astra Control Center.

. Use the following command to determine if you have the plug-in installed:
+
----
kubectl astra
----

This command should provide the kubectl plugin help. If the command returns an error, install the plugin using these link:../get-started/install_acc.html#install-the-netapp-astra-kubectl-plugin[instructions].

== Add the images to your local registry

. Complete the appropriate step sequence for your container engine: 

// start tabbed block for docker and podman approaches

[role="tabbed-block"]
====

.Docker
--
. Change to the Astra directory:
+
[source,sh]
----
cd acc
----
. [[substep_image_local_registry_push]]Push the package images in the Astra Control Center image directory to your local registry. Make the following substitutions before running the command:
+

* Replace BUNDLE_FILE with the name of the Astra Control bundle file (`acc.manifest.yaml`).
* Replace MY_FULL_REGISTRY_PATH with the URL of the Docker repository.  The URL must include the exact directory that contains the images.
* Replace MY_REGISTRY_USER with the user name.
* Replace MY_REGISTRY_TOKEN with an authorized token for the registry.
+
[source,sh]
----
kubectl astra packages push-images -m BUNDLE_FILE -r MY_FULL_REGISTRY_PATH -u MY_REGISTRY_USER -p MY_REGISTRY_TOKEN
----
--

.Podman
--
. Log in to your registry:
+
[source,sh]
----
podman login [your_registry_path]
----
. Run the following script, making the <YOUR_REGISTRY> substitution as noted in the comments:
+
[source,sh]
----
# You need to be at the root of the tarball.
# You should see these files to confirm correct location:
#   acc.manifest.yaml
#   acc/

# Replace <YOUR_REGISTRY> with your own registry (e.g registry.customer.com or registry.customer.com/testing, etc..)
export REGISTRY=<YOUR_REGISTRY>
export PACKAGENAME=acc
export PACKAGEVERSION=22.08.1-26
export DIRECTORYNAME=acc
for astraImageFile in $(ls ${DIRECTORYNAME}/images/*.tar) ; do
  # Load to local cache
  astraImage=$(podman load --input ${astraImageFile} | sed 's/Loaded image(s): //')
 
  # Remove path and keep imageName.
  astraImageNoPath=$(echo ${astraImage} | sed 's:.*/::')
 
  # Tag with local image repo.
  podman tag ${astraImage} ${REGISTRY}/netapp/astra/${PACKAGENAME}/${PACKAGEVERSION}/${astraImageNoPath}
 
  # Push to the local repo.
  podman push ${REGISTRY}/netapp/astra/${PACKAGENAME}/${PACKAGEVERSION}/${astraImageNoPath}
done
----
--

====

// end tabbed block

== Install the updated Astra Control Center operator

. Change the directory:
+
----
cd manifests
----

. Edit the Astra Control Center operator deployment yaml (`astra_control_center_operator_deploy.yaml`) to refer to your local registry and secret.
+
----
vim astra_control_center_operator_deploy.yaml
----

.. If you use a registry that requires authentication, replace the default line of `imagePullSecrets: []` with the following:
+
----
imagePullSecrets:
- name: <name_of_secret_with_creds_to_local_registry>
----

.. Change `[your_registry_path]` for the `kube-rbac-proxy` image to the registry path where you pushed the images in a <<substep_image_local_registry_push,previous step>>.
.. Change `[your_registry_path]` for the `acc-operator` image to the registry path where you pushed the images in a <<substep_image_local_registry_push,previous step>>.
//DOC-4167/ASTRACTL-16917/PI5
.. Add the following values to the `env` section:
+
----
- name: ACCOP_HELM_UPGRADETIMEOUT
  value: 300m
----
+
[subs=+quotes]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    control-plane: controller-manager
  name: acc-operator-controller-manager
  namespace: netapp-acc-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      control-plane: controller-manager
  template:
    metadata:
      labels:
        control-plane: controller-manager
    spec:
      containers:
      - args:
        - --secure-listen-address=0.0.0.0:8443
        - --upstream=http://127.0.0.1:8080/
        - --logtostderr=true
        - --v=10
        *image: [your_registry_path]/kube-rbac-proxy:v4.8.0*
        name: kube-rbac-proxy
        ports:
        - containerPort: 8443
          name: https
      - args:
        - --health-probe-bind-address=:8081
        - --metrics-bind-address=127.0.0.1:8080
        - --leader-elect
        command:
        - /manager
        env:
        - name: ACCOP_LOG_LEVEL
          value: "2"
        *- name: ACCOP_HELM_UPGRADETIMEOUT*
          *value: 300m*
        *image: [your_registry_path]/acc-operator:[version x.y.z]*
        imagePullPolicy: IfNotPresent
      *imagePullSecrets: []*
----

. Install the updated Astra Control Center operator:
+
----
kubectl apply -f astra_control_center_operator_deploy.yaml
----
+
Sample response:
+
----
namespace/netapp-acc-operator unchanged
customresourcedefinition.apiextensions.k8s.io/astracontrolcenters.astra.netapp.io configured
role.rbac.authorization.k8s.io/acc-operator-leader-election-role unchanged
clusterrole.rbac.authorization.k8s.io/acc-operator-manager-role configured
clusterrole.rbac.authorization.k8s.io/acc-operator-metrics-reader unchanged
clusterrole.rbac.authorization.k8s.io/acc-operator-proxy-role unchanged
rolebinding.rbac.authorization.k8s.io/acc-operator-leader-election-rolebinding unchanged
clusterrolebinding.rbac.authorization.k8s.io/acc-operator-manager-rolebinding configured
clusterrolebinding.rbac.authorization.k8s.io/acc-operator-proxy-rolebinding unchanged
configmap/acc-operator-manager-config unchanged
service/acc-operator-controller-manager-metrics-service unchanged
deployment.apps/acc-operator-controller-manager configured
----

. Verify pods are running:
+
----
kubectl get pods -n netapp-acc-operator
----

== Upgrade Astra Control Center

. Edit the Astra Control Center custom resource (CR) and change the Astra version (`astraVersion` inside of `Spec`) number to the latest:
+
----
kubectl edit acc -n [netapp-acc or custom namespace]
----
+
. Verify that your image registry path matches the registry path you pushed the images to in a <<substep_image_local_registry_push,previous step>>. Update `imageRegistry` inside of `Spec` if the registry has changed since your last installation.

. Add the following lines within `additionalValues` inside of `Spec` in the Astra Control Center CR:
+
----
additionalValues:
    nautilus:
      startupProbe:
        periodSeconds: 30
        failureThreshold: 600
----

+
After you save and exit the file editor, the changes will be applied and the upgrade will begin.

. (Optional) Verify that the pods terminate and become available again:
+
----
watch kubectl get pods -n [netapp-acc or custom namespace]
----

. Wait for the Astra status conditions to indicate that the upgrade is complete and ready (`True`):
+
----
kubectl get acc -n [netapp-acc or custom namespace]
----
+
Response:
+
----
NAME    UUID                                      VERSION     ADDRESS         READY
astra   ACC-9aa5fdae-4214-4cb7-9976-5d8b4c0ce27f  22.11.0-24  10.111.111.111  True
----
+
NOTE: To monitor upgrade status during the operation, use the following command: `kubectl get -o yaml -n [netapp-acc or custom namespace] acc | grep -i upgrading`.

. Log back in to the UI and verify that all managed clusters and apps are still present and protected.
. If the operator did not update the Cert-manager, upgrade third-party services next.


== Upgrade third-party services (Optional)
The third-party services Traefik and Cert-manager are not upgraded during earlier upgrade steps. You can optionally upgrade them using the procedure described here or retain existing service versions if your system requires it.

* *Traefik*: By default, Astra Control Center manages the lifecycle of the Traefik deployment.  Setting `externalTraefik` to `false` (default) indicates that no external Traefik exists in the system and and Traefik is being installed and managed by Astra Control Center. In this case,  `externalTraefik` is set to `false`.
+
On the other hand, if you have your own Traefik deployment, set `externalTraefik` to `true`. In this case, you maintain the deployment and Astra Control Center will not upgrade the CRDs, unless `shouldUpgrade` is set to `true`.

* *Cert-manager*: By default, Astra Control Center installs the cert-manager (and CRDs) unless you set `externalCertManager` to `true`. Set `shouldUpgrade` to `true` to have Astra Control Center upgrade the CRDs.

Traefik is upgraded if any of the following conditions are met:

* externalTraefik: false
* externalTraefik: true AND shouldUpgrade: true.

.Steps

. Edit the `acc` CR:
+
----
kubectl edit acc -n [netapp-acc or custom namespace]
----

. Change the `externalTraefik` field and the `shouldUpgrade` field to either `true` or `false` as needed.
+
----
crds:
    externalTraefik: false
    externalCertManager: false
    shouldUpgrade: false
----

== Verify system status

. Log in to Astra Control Center.
. Verify that all your managed clusters and apps are still present and protected.

== Set up ingress for load balancing

You can set up a Kubernetes ingress object that manages external access to the services, such as load balancing in a cluster.

* Default upgrade uses the generic ingress deployment. In this case, you will also need to set up an ingress controller or ingress resource.

* If you don't want an ingress controller and want to retain what you already have, set `ingressType` to `AccTraefik`.

NOTE: For additional details about the service type of "LoadBalancer" and ingress, see link:../get-started/requirements.html[Requirements].

The steps differ depending on the type of ingress controller you use:

* Nginx ingress controller
* OpenShift ingress controller

.What you'll need

* In the CR spec,
** If `crd.externalTraefik` is present, it should be set to `false` OR
** If `crd.externalTraefik` is `true`, `crd.shouldUpgrade` should also be `true`.

* The required https://kubernetes.io/docs/concepts/services-networking/ingress-controllers[ingress controller] should already be deployed.
* The https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class[ingress class] corresponding to the ingress controller should already be created.
* You are using Kubernetes versions between and including v1.19 and v1.21.

.Steps for Nginx ingress controller

. Use the existing secret `secure-testing-cert` or create a secret of type `kubernetes.io/tls` for a TLS private key and certificate in `netapp-acc` (or custom-named) namespace as described in https://kubernetes.io/docs/concepts/configuration/secret/#tls-secrets[TLS secrets].
. Deploy an ingress resource in `netapp-acc` (or custom-named) namespace for either a deprecated or a new schema:
.. For a deprecated schema, follow this sample:

+
----
apiVersion: extensions/v1beta1
kind: IngressClass
metadata:
  name: ingress-acc
  namespace: [netapp-acc or custom namespace]
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  tls:
  - hosts:
    - <ACC address>
    secretName: [tls secret name]
  rules:
  - host: [ACC address]
    http:
      paths:
      - backend:
        serviceName: traefik
        servicePort: 80
        pathType: ImplementationSpecific
----

.. For a new schema, follow this example:

+
----
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: netapp-acc-ingress
  namespace: [netapp-acc or custom namespace]
spec:
  ingressClassName: [class name for nginx controller]
  tls:
  - hosts:
    - <ACC address>
    secretName: [tls secret name]
  rules:
  - host: <ACC address>
    http:
      paths:
        - path:
          backend:
            service:
              name: traefik
              port:
                number: 80
          pathType: ImplementationSpecific
----

.Steps for OpenShift ingress controller

. Procure your certificate and get the key, certificate, and CA files ready for use by the OpenShift route.
. Create the OpenShift route:
+
----
oc create route edge --service=traefik --port=web -n [netapp-acc or custom namespace] --insecure-policy=Redirect --hostname=<ACC address> --cert=cert.pem --key=key.pem
----

=== Verify ingress set up

You can verify the ingress set up before you continue.

. Ensure that Traefik has changed to `clusterIP` from Loadbalancer:
+
----
kubectl get service traefik -n [netapp-acc or custom namespace]
----

. Verify routes in Traefik:
+
----
Kubectl get ingressroute ingressroutetls -n [netapp-acc or custom namespace]
-o yaml | grep "Host("
----
+
NOTE: The result should be empty.
